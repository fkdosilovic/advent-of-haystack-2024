{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3: Making Answers Bright with Multi-Query RAG Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-10 20:12:46--  https://raw.githubusercontent.com/amankharwal/Website-data/master/bbc-news-data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5080260 (4.8M) [text/plain]\n",
      "Saving to: â€˜bbc-news-data.csv.3â€™\n",
      "\n",
      "bbc-news-data.csv.3   0%[                    ]       0  --.-KB/s               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbc-news-data.csv.3 100%[===================>]   4.84M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2024-12-10 20:12:46 (51.6 MB/s) - â€˜bbc-news-data.csv.3â€™ saved [5080260/5080260]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/amankharwal/Website-data/master/bbc-news-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List\n",
    "\n",
    "from haystack import Document\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and index the news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_documents(file: str) -> List[Document]:\n",
    "    with open(file, \"r\") as file:\n",
    "        reader = csv.reader(file, delimiter=\"\\t\")\n",
    "        next(reader, None)  # skip the headers\n",
    "        docs = []\n",
    "        for row in reader:\n",
    "            category = row[0].strip()\n",
    "            title = row[2].strip()\n",
    "            text = row[3].strip()\n",
    "            docs.append(Document(content=text, meta={\"category\": category, \"title\": title}))\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eab85ae5b84cd2adfc5be621f2d808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 2225}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "doc_store = InMemoryDocumentStore()\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\"embedder\", SentenceTransformersDocumentEmbedder(model=embedding_model))\n",
    "indexing_pipeline.add_component(\"writer\", DocumentWriter(doc_store, policy=DuplicatePolicy.OVERWRITE))\n",
    "indexing_pipeline.connect(\"embedder\", \"writer\")\n",
    "\n",
    "documents = read_documents(\"bbc-news-data.csv\")\n",
    "indexing_pipeline.run({\"embedder\":{\"documents\": documents}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a custom component MultiQueryGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_generator_template = \"\"\"\n",
    "You are an AI language model assistant. Your task is to generate a different version of the\n",
    "given user question by expanding the meaning of it.\n",
    "By generating different perspective on the user question, you will help gather diverse information that will be useful to answer the user question in more comprehensive manner.\n",
    "The generated question should be concise. Do not just rephrase the question, think about the other topics that are relevent to the user question.\n",
    "\n",
    "Provide alternative question only.\n",
    "Original question: {{question}}\n",
    "Alternative: question:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import component\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "@component\n",
    "class MultiQueryGenerator:\n",
    "    def __init__(self, prompt_builder: PromptBuilder = None, generator: OpenAIGenerator = None):\n",
    "        # You need to define a Generator and a PromptBuilder to pass to that generator\n",
    "        # The template of the PromptBuilder will have two variables:\n",
    "        #    - 'query' a string,\n",
    "        #    - 'n_variations' the number of variations of the query string to generate\n",
    "        if prompt_builder is None:\n",
    "            prompt_builder = PromptBuilder(template=query_generator_template, required_variables=[\"question\"])\n",
    "        if generator is None:\n",
    "            generator = OpenAIGenerator()\n",
    "\n",
    "        self.prompt_builder = prompt_builder\n",
    "        self.generator = generator\n",
    "\n",
    "    @component.output_types(queries=List[str])\n",
    "    def run(self, query: str, n_variations: int = 3):\n",
    "        # You need build a prompt filling in the variables 'query' and 'n_variations'\n",
    "        prompt_dict = self.prompt_builder.run(template_variables={\"question\": query})\n",
    "        # This prompt is then pased to a generator, and you need to collect the result\n",
    "        # You should return a List[str] with the original query, plus, the 'n_variations' generated by the LLM\n",
    "        print(f\"{query=}\")\n",
    "        generated_queries = self.generator.run(**prompt_dict, generation_kwargs={\"n\": n_variations})\n",
    "        print(f\"{generated_queries[\"replies\"]}\")\n",
    "        queries = [query] + generated_queries[\"replies\"]\n",
    "        return {\"queries\": queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_query_generator = MultiQueryGenerator()\n",
    "# multi_query_generator.run(\"What is popular in the music industry today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n",
    "\n",
    "@component\n",
    "class MultiQueryHandler:\n",
    "    def __init__(self, document_store: InMemoryDocumentStore, embedding_model: str):\n",
    "        # Initialize your SentenceTransformersTextEmbedder and InMemoryEmbeddingRetriever here\n",
    "        self.retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "        self.embedder = SentenceTransformersTextEmbedder(model=embedding_model)\n",
    "        # Ensure that the embedding model used for indexing is the same one used for querying in SentenceTransformersTextEmbedder\n",
    "\n",
    "    @component.output_types(answers=List[Document])\n",
    "    def run(self, queries: List[str], top_k: int = 3):\n",
    "        # You need to initialize an embedder to embed each query in `queries`\n",
    "        self.embedder.warm_up()\n",
    "        query_embeddings = [self.embedder.run(query)[\"embedding\"] for query in queries]\n",
    "        # Each query will be used to retrieve a List[Document] from the document_store\n",
    "        documents = [document for query_embedding in query_embeddings for document in self.retriever.run(query_embedding, top_k=top_k)[\"documents\"]]\n",
    "        # You then need to pack all those into a single List[Document] and return it\n",
    "        return {\"answers\": documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_query_handler = MultiQueryHandler(document_store=doc_store, embedding_model=embedding_model)\n",
    "# multi_query_handler.run([\"What is popular in the music industry today?\", \"Which artists are trending in the music industry today?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the RAG Pipeline with Multi-Query Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import PromptBuilder, AnswerBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.joiners import DocumentJoiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You have to answer the following question based on the given context information only.\n",
    "If the context is empty or just a '\\\\n' answer with None, example: \"None\".\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x70261613fce0>\n",
       "ðŸš… Components\n",
       "  - multi_query_generator: MultiQueryGenerator\n",
       "  - multi_query_handler: MultiQueryHandler\n",
       "  - reranker: DocumentJoiner\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "  - answer_builder: AnswerBuilder\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - multi_query_generator.queries -> multi_query_handler.queries (List[str])\n",
       "  - multi_query_handler.answers -> reranker.documents (List[Document])\n",
       "  - reranker.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)\n",
       "  - llm.replies -> answer_builder.replies (List[str])\n",
       "  - llm.meta -> answer_builder.meta (List[Dict[str, Any]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "\n",
    "# add components\n",
    "pipeline.add_component(\"multi_query_generator\", MultiQueryGenerator())\n",
    "pipeline.add_component(\"multi_query_handler\", MultiQueryHandler(document_store=doc_store, embedding_model=embedding_model))\n",
    "pipeline.add_component(\"reranker\", DocumentJoiner(join_mode=\"reciprocal_rank_fusion\"))\n",
    "pipeline.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "pipeline.add_component(\"llm\", OpenAIGenerator())\n",
    "pipeline.add_component(\"answer_builder\", AnswerBuilder())\n",
    "\n",
    "# connect components\n",
    "pipeline.connect(\"multi_query_generator.queries\", \"multi_query_handler.queries\")\n",
    "pipeline.connect(\"multi_query_handler.answers\", \"reranker.documents\")\n",
    "pipeline.connect(\"reranker\", \"prompt_builder.documents\")\n",
    "pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "pipeline.connect(\"llm.replies\", \"answer_builder.replies\")\n",
    "pipeline.connect(\"llm.meta\", \"answer_builder.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"Can you give me some suggestions do you have for Christmas presents? Please provide a variety of options.\"\n",
    "# question = \"What is popular in the music industry today?\"\n",
    "question = \"How are cybersecurity threats evolving with new technologies?\"\n",
    "# question = \"What does UK do to prevent piracy in music industry?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='How are cybersecurity threats evolving with new technologies?'\n",
      "['In what ways are emerging technologies influencing the nature and complexity of cybersecurity threats, and what measures can organizations implement to mitigate these risks?', 'What are the implications of emerging technologies, like artificial intelligence and blockchain, on the nature and tactics of cybersecurity threats?', 'In what ways are emerging technologies influencing the nature and complexity of cybersecurity threats, and how can organizations adapt their defenses accordingly?']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eaf7748c354a5da7cd40bf385ac0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a520651651c546bc87225f60f99ed48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82620eada5ca444d89a15e14d5295724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c67f571678f4d67a1125be71d7bed75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_variations = 3\n",
    "top_k = 3\n",
    "\n",
    "result = pipeline.run({\n",
    "    'multi_query_generator': {'query': question, 'n_variations': n_variations},\n",
    "     'multi_query_handler': {'top_k': top_k},\n",
    "     'prompt_builder': {'template_variables': {'question': question}},\n",
    "     'answer_builder': {'query': question}\n",
    "     }, include_outputs_from={\"multi_query_generator\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Questions:\n",
      "\n",
      "How are cybersecurity threats evolving with new technologies?\n",
      "In what ways are emerging technologies influencing the nature and complexity of cybersecurity threats, and what measures can organizations implement to mitigate these risks?\n",
      "What are the implications of emerging technologies, like artificial intelligence and blockchain, on the nature and tactics of cybersecurity threats?\n",
      "In what ways are emerging technologies influencing the nature and complexity of cybersecurity threats, and how can organizations adapt their defenses accordingly?\n",
      "\n",
      "\n",
      "Answer:\n",
      "\n",
      "Cybersecurity threats are evolving as tech-savvy criminals increasingly exploit new technologies to perpetrate crimes. The creation of malware is shifting from random virus production aimed at causing disruption to more sophisticated and targeted attacks designed for direct financial gain. Criminals are now focusing on methods that allow them to con people, steal valuable data, or take over home PCs. \n",
      "\n",
      "The categorization of viruses has become more complex, as contemporary malware often combines multiple technical tricks in one package, making them harder to classify traditionally. This new wave of malware spreads through various means, including exploiting software vulnerabilities, using social engineering tactics, and self-propagation like worms. \n",
      "\n",
      "Spyware, phishing, and Distributed Denial-of-Service (DDoS) attacks are among the prevalent threats, often utilizing bot nets composed of infected machines to execute their objectives covertly. Criminals are also targeting specific industries like online gambling, demonstrating an organized and financially motivated approach to cybercrime. \n",
      "\n",
      "Moreover, the vast number of existing malicious programs is increasing dramatically, with estimates suggesting they could reach unprecedented levels. As threats evolve, firms are also adapting their defenses, deploying intelligent network systems that can monitor traffic patterns, detect anomalies, and automatically mitigate attacks, indicating a constant arms race between cybercriminals and cybersecurity measures.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nQuestions:\\n\")\n",
    "for q in result['multi_query_generator']['queries']:\n",
    "    print(q)\n",
    "print(\"\\n\\nAnswer:\\n\")\n",
    "print(result['answer_builder']['answers'][0].data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
